{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Citation Recommendation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfpFgG4HCCbE",
        "outputId": "a0164819-6fe1-4a46-c34f-9e166d22dbf2"
      },
      "source": [
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "repubXtrCIM-",
        "outputId": "f460bbe9-380e-4f29-8906-ab5f10072a95"
      },
      "source": [
        "!pip install transformers\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK37KkRZCQix"
      },
      "source": [
        "# !pip install wget"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4K3SB0gCdjR"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "\n",
        "class BERTContrastive(nn.Module):\n",
        "    def __init__(self, train=True, dropout=0.1):\n",
        "        super(BERTContrastive, self).__init__()\n",
        "        # use pretrained BERT\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear1 = nn.Linear(768, 512)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        print(\"Done loading model\")\n",
        "        # if train:\n",
        "        #     self.bert.train()\n",
        "        # else:\n",
        "        #     self.bert.eval()\n",
        "        #     for param in self.bert.parameters():\n",
        "        #         param.requires_grad = False\n",
        "        # self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def forward(self, input_ids, masks=None):\n",
        "        # input_ids = torch.tensor(self.tokenizer.encode(inputs)).unsqueeze(0)  # Batch size 1\n",
        "        print(input_ids.size(), masks.size())\n",
        "        _, pooled_output = self.bert(input_ids, attention_mask=masks)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = F.relu(self.linear1(dropout_output))\n",
        "        linear_output = F.relu(self.linear2(linear_output))\n",
        "        # print(pooled_output)\n",
        "        # last_hidden_states = outputs[0]\n",
        "        # cls = last_hidden_states[0]\n",
        "        return linear_output\n",
        "\n",
        "class BERTClassification(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BERTClassification, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks)\n",
        "        print(tokens.size(), masks.size(), pooled_output.size())\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1l7Z4Id72KZ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "import pickle\n",
        "\n",
        "\n",
        "class Preprocessing:\n",
        "    def __init__(self, file, taskname):\n",
        "        self.file = file\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "        self.taskname = taskname\n",
        "\n",
        "\n",
        "    def preprocess(self):\n",
        "        df = pd.read_csv(self.file, error_bad_lines=False, encoding='latin-1')\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        abstract1 = list(df['paperAbstract1'])\n",
        "        abstract2 = list(df['paperAbstract2'])\n",
        "        labels = torch.tensor(list(df['label'])).unsqueeze(dim=1).float()\n",
        "\n",
        "        if self.taskname == \"Classification\":\n",
        "            encoded_abstract = self.tokenizer(abstract1, abstract2, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "            # print(encoded_abstract)\n",
        "            # print(labels.size())\n",
        "            pickle.dump(encoded_abstract, open(\"BERTClassificationEncodings.pkl\", 'wb'))\n",
        "            pickle.dump(labels, open(\"BERTClassificationLabels.pkl\", 'wb'))\n",
        "\n",
        "        else:\n",
        "            encoded_abstract1 = self.tokenizer(abstract1, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "            encoded_abstract2 = self.tokenizer(abstract2, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "            # print(encoded_abstract1, encoded_abstract2)\n",
        "\n",
        "            # print(encoded_abstract2, encoded_abstract1, labels.size())\n",
        "\n",
        "            pickle.dump(encoded_abstract1, open(\"BERTContrastiveEncodings.pkl\", 'wb'))\n",
        "            pickle.dump(encoded_abstract2, open(\"BERTContrastiveEncodings1.pkl\", 'wb'))\n",
        "            pickle.dump(labels, open(\"BERTContrastiveLabels.pkl\", 'wb'))\n",
        "\n",
        "        # print(labels, type(labels))\n",
        "        print(\"Preprocessing done!!\")\n",
        "\n",
        "\n",
        "# def main():\n",
        "#     # testing preprocess for contrastive version\n",
        "#     preprocessCls = Preprocessing('data/test.csv', \"Classification\")\n",
        "#     preprocessCls.preprocess()\n",
        "\n",
        "#     preprocessCls = Preprocessing('data/test.csv', \"Contrastive\")\n",
        "#     preprocessCls.preprocess()\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4Kuvd8W9rMa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7phsAv-677-g"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizer, AdamW\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler\n",
        "import pickle\n",
        "# from model import *\n",
        "\n",
        "\n",
        "def contrastiveEuclideanLoss(output1, output2, target, size_average=True):\n",
        "    distances = (output2 - output1).pow(2).sum(1)  # squared distances\n",
        "    losses = 0.5 * (target.float() * distances +\n",
        "                (1 + -1 * target).float() * F.relu(0 - (distances + 0.00000001).sqrt()).pow(2))\n",
        "    return losses.mean() if size_average else losses.sum()\n",
        "\n",
        "def trainBERTClassification(encodings, labels):\n",
        "\n",
        "    model = BERTClassification().to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    dataset = TensorDataset(encodings['input_ids'], encodings['token_type_ids'], encodings['attention_mask'], labels)\n",
        "    sampler = RandomSampler(dataset)\n",
        "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=8)\n",
        "    epochs = 20\n",
        "    count = 0\n",
        "\n",
        "    print(\"Starting to train!!\")\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        batch_loss = 0\n",
        "\n",
        "        for input_ids, _, attention_mask, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            prob = model(input_ids, attention_mask)\n",
        "            print(prob)\n",
        "            loss_func = nn.BCELoss()\n",
        "            loss = loss_func(prob, labels)\n",
        "            epoch_loss += loss.item()\n",
        "            batch_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            count += 1\n",
        "\n",
        "            if count % 2000 == 1999:\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, count + 1, batch_loss / 2000))\n",
        "                batch_loss = 0.0\n",
        "\n",
        "        print(\"EPOCH Loss ====================\", str(epoch_loss))\n",
        "\n",
        "    print(\"Training complete!!\")\n",
        "\n",
        "\n",
        "def trainBERTContrastive(encoding1,encoding2, labels): \n",
        "    print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "\n",
        "   \n",
        "    model = BERTContrastive()\n",
        "\n",
        "    model = model.to(device)\n",
        "    print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    print(encoding1['input_ids'].size())\n",
        "    dataset = TensorDataset(encoding1['input_ids'], encoding1['token_type_ids'], encoding1['attention_mask'], encoding2['input_ids'], encoding2['token_type_ids'], encoding2['attention_mask'], labels)\n",
        "    sampler = RandomSampler(dataset)\n",
        "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=8)\n",
        "    epochs = 20\n",
        "    count = 0\n",
        "\n",
        "    print(\"Starting to train!!\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        batch_loss = 0\n",
        "\n",
        "        for input_ids1, _, attention_mask1, input_ids2, _, attention_mask2, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            emd1 = model(input_ids1, attention_mask1)\n",
        "            emd2 = model(input_ids2, attention_mask2)\n",
        "\n",
        "\n",
        "            # criterion = nn.CosineEmbeddingLoss()\n",
        "            # criterion = contrastiveEuclideanLoss\n",
        "            criterion = nn.MarginRankingLoss()\n",
        "            loss = criterion(emd1, emd2, 2 * labels - 1)\n",
        "            epoch_loss += loss.item()\n",
        "            batch_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            count += 1\n",
        "\n",
        "            if count % 2000 == 1999:\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, count + 1, batch_loss / 2000))\n",
        "                batch_loss = 0.0\n",
        "\n",
        "        print(\"EPOCH Loss ====================\", str(epoch_loss))\n",
        "\n",
        "    print(\"Training complete!!\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JURdyz1H8EVY",
        "outputId": "002b6ec3-2100-4b53-a757-a9a5f77064d2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random as rn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "import pickle\n",
        "\n",
        "# from train import *\n",
        "# from preprocess import *\n",
        "\n",
        "\n",
        "def main():\n",
        "    \n",
        "    rn.seed(321)\n",
        "    np.random.seed(321)\n",
        "    torch.manual_seed(321)\n",
        "    torch.cuda.manual_seed(321)\n",
        "\n",
        "    preprocessed = False\n",
        "\n",
        "    task = \"Classification\"\n",
        "    task = \"Contrastive\"\n",
        "\n",
        "\n",
        "    if not preprocessed:\n",
        "        preprocessCls = Preprocessing('data_dummy.csv', task)\n",
        "        preprocessCls.preprocess()\n",
        "\n",
        "        # preprocessCls = Preprocessing('data/data_dummy.csv', task)\n",
        "        # preprocessCls.preprocess()\n",
        "\n",
        "\n",
        "    if task == \"Classification\":\n",
        "        encodings = pickle.load(open(\"BERT\" + task + \"Encodings.pkl\", 'rb'))\n",
        "        labels = pickle.load(open(\"BERT\" + task + \"Labels.pkl\", 'rb'))\n",
        "        trainBERTClassification(encodings.to(device), labels.to(device))\n",
        "\n",
        "\n",
        "    else:\n",
        "        encodings1 = pickle.load(open(\"BERT\" + task + \"Encodings.pkl\", 'rb'))\n",
        "        labels = pickle.load(open(\"BERT\" + task + \"Labels.pkl\", 'rb'))\n",
        "        encodings2 = pickle.load(open(\"BERT\" + task + \"Encodings.pkl\", 'rb'))\n",
        "        print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "\n",
        "\n",
        "        trainBERTContrastive(encodings1.to(device), encodings2.to(device), labels.to(device))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing done!!\n",
            "0.0M\n",
            "1.51808M\n",
            "Done loading model\n",
            "441.58208M\n",
            "torch.Size([76, 416])\n",
            "Starting to train!!\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.15673904679715633\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.1210169643163681\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.10408479627221823\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.08381470898166299\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.07221556175500154\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.06628649309277534\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.05156438611447811\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.04199972213245928\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.03503217198885977\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.029887410812079906\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.026236542966216803\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.023127273772843182\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.02225857914891094\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.01938717858865857\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.01751901360694319\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.01631738105788827\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.015464978408999741\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.013533756835386157\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.012924333335831761\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "EPOCH Loss ==================== 0.011927208804991096\n",
            "Training complete!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rR7B4Ca8LH0"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}