{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "from csv import DictReader\n",
    "\n",
    "data_dblp = []\n",
    "with open('Desktop/data_dummy.csv', encoding=\"utf8\", errors='ignore') as read_obj:\n",
    "    dict_reader = DictReader(read_obj)\n",
    "    data_dblp = list(dict_reader)\n",
    "\n",
    "data_dblp = data_dblp[:80]\n",
    "print(len(data_dblp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dot, Reshape, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "The emergence of advanced technologies such as InfiniBand and Non-Volatile Memory together with decreasing in DRAM prices has enabled us to build ultra-low latency in-memory stores for backing real-time and large-scale services. Many studies have taken those opportunities to accelerate lookup operations of key-value stores. Meanwhile, there is a lack of researches that utilize them for improving range query performance. This paper reports a detailed performance analysis of range query execution of in-memory stores. Our findings show that in modern architecture, copying/serialization data for transmission over network is the major overhead of range query processing. To solve this issue, several methods could be considered, such as parallelism, caching, and utilizing RDMA Read. We have conducted some experiments to evaluate their potentials and surprisingly, the outcomes revealed that none of those performed well in every scenario. Optimizing performance gain when employing those techniques requires us to carefully address user behaviors, characteristics of data and even system architecture.\n"
     ]
    }
   ],
   "source": [
    "pairsData = []\n",
    "\n",
    "for data in data_dblp:\n",
    "    pairsData.append(tuple((data['paperAbstract1'], data['paperAbstract2'], data['label'])))\n",
    "\n",
    "print(len(pairsData))\n",
    "print(pairsData[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_index = {data[0]: idx for idx, data in enumerate(pairsData)}\n",
    "target_index = {data[1]: idx for idx, data in enumerate(pairsData)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(source_index)\n",
    "#print(target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "finalData = []\n",
    "\n",
    "for data in data_dblp:\n",
    "    finalData.append(tuple((source_index[data['paperAbstract1']], target_index[data['paperAbstract2']], data['label'])))\n",
    "    \n",
    "print(len(finalData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "source (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_embedding (Embedding)    (None, 1, 5)         400         source[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "target_embedding (Embedding)    (None, 1, 5)         350         target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           source_embedding[0][0]           \n",
      "                                                                 target_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1)            0           dot_product[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            2           reshape_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 752\n",
      "Trainable params: 752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 5\n",
    "def model():\n",
    "    \n",
    "    source = Input(name = 'source', shape = [1])\n",
    "    target = Input(name = 'target', shape = [1])\n",
    "    \n",
    "    source_embedding = Embedding(name = 'source_embedding',input_dim = len(source_index),\n",
    "                               output_dim = embedding_size)(source)\n",
    "    \n",
    "    target_embedding = Embedding(name = 'target_embedding',input_dim = len(target_index),\n",
    "                               output_dim = embedding_size)(target)\n",
    "    \n",
    "    final_layer = Reshape([1])(Dot(name = 'dot_product', normalize = True, axes = 2)([source_embedding, target_embedding]))\n",
    "    \n",
    "    final_layer = Dense(1, activation = 'sigmoid')(final_layer)\n",
    "    model = Model(inputs = [source, target], outputs = final_layer)\n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(100)\n",
    "\n",
    "batch_size = 8\n",
    "print(len(finalData))\n",
    "def batchifier(finalData):\n",
    "    \"\"\"Generate batches of samples for training\"\"\"\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    \n",
    "    while True:\n",
    "        for idx, (source_id, target_id, label) in enumerate(random.sample(finalData, batch_size)):\n",
    "            batch[idx, :] = (source_id, target_id, label)\n",
    "\n",
    "        np.random.shuffle(batch)\n",
    "        #print(len(batch))\n",
    "        yield {'source': batch[:, 0], 'target': batch[:, 1]}, batch[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = batchifier(finalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit_generator(gen, epochs = 2, steps_per_epoch = 2,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
