{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109051\n",
      "OrderedDict([('id1', '44cc6070-b7e5-4fba-90a0-e0ed84e85775'), ('id2', '01216a98-f91b-4d14-9ae6-59a0ecf0365d'), ('paperAbstract1', 'Regression testing is the verification that previously functioning software remains after a change. In this paper we report on a systematic review of empirical evaluations of regression test selection techniques published in major software engineering journals and conferences. Out of 2923 papers analyzed in this systematic review we identified 28 papers reporting on empirical comparative evaluations of regression test selection techniques. They report on 38 unique studies (23 experiments and 15 case studies) and in total 32 different techniques for regression test selection are evaluated. Our study concludes that no clear picture of the evaluated techniques can be provided based on existing empirical evidence except for a small group of related techniques. Instead we identified a need for more and better empirical studies were concepts are evaluated rather than small variations. It is also necessary to carefully consider the context in which studies are undertaken.'), ('paperAbstract2', \"Regression testing is expensive and may consume much of organizations' software development budgets. Thus it is of interest to reduce the total time devoted to test execution by using test selection techniques. Many techniques have been proposed but few have been evaluated on real-world large scale systems. In this paper we report on an empirical evaluation of using the class firewall regression test selection technique in combination with scenario testing on a large scale industrial software system using the Java byte code in the analysis. The study was performed on a large complex distributed software system in one of Sweden's largest banks. Effects of using scenario testing together with regression test selection are reported. The results are that not all test cases were selected by the class firewall selection technique. Using scenario testing where test cases are dependent affects the number of test cases selected as do the location and number of changes in the system.\"), ('label', '1')])\n",
      "81788 *************** 27263\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from csv import DictReader\n",
    "import random\n",
    "import math\n",
    "\n",
    "data_dblp = []\n",
    "with open('Desktop/Data_D/data.csv', encoding=\"utf8\", errors='ignore') as read_obj:\n",
    "    dict_reader = DictReader(read_obj)\n",
    "    data = list(dict_reader)\n",
    "    for d in data:\n",
    "        if d['label'] == '0' or d['label'] == '1':\n",
    "            d['paperAbstract1'] = d['paperAbstract1'].strip()\n",
    "            d['paperAbstract2'] = d['paperAbstract2'].strip()\n",
    "            data_dblp.append(d)\n",
    "        \n",
    "print(len(data_dblp))\n",
    "print(data_dblp[0])\n",
    "\n",
    "random.shuffle(data_dblp)\n",
    "train_data = data_dblp[0:math.floor(0.75* (len(data_dblp)))]\n",
    "test_data = data_dblp[math.floor(0.75 * (len(data_dblp))):len(data_dblp)]\n",
    "\n",
    "print(len(train_data), \"***************\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dot, Reshape, Dense\n",
    "from keras.models import Model,load_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsData = []\n",
    "\n",
    "for data in train_data:\n",
    "    pairsData.append(tuple((data['paperAbstract1'], data['paperAbstract2'], data['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pairsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntemp = []\\nfor k,v in source_index.items():\\n    temp.append(v)\\ntemp.sort()\\nprint(temp)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "source_index = {}\n",
    "#source_index = {data[0]: idx for idx, data in enumerate(pairsData, start = 0)}\n",
    "m = 0\n",
    "\n",
    "for idx in range(len(pairsData)):\n",
    "    if not pairsData[idx][0] in source_index:\n",
    "        source_index[pairsData[idx][0]] = m\n",
    "        m = m + 1\n",
    "\n",
    "print(len(source_index))\n",
    "\n",
    "'''\n",
    "temp = []\n",
    "for k,v in source_index.items():\n",
    "    temp.append(v)\n",
    "temp.sort()\n",
    "print(temp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstrcheck = []\\nfor idx, data in enumerate(pairsData):\\n    strcheck.append(data[1])\\n    \\nprint(len(strcheck))\\nstrcheck = set(strcheck)\\nprint(len(strcheck))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking\n",
    "'''\n",
    "strcheck = []\n",
    "for idx, data in enumerate(pairsData):\n",
    "    strcheck.append(data[1])\n",
    "    \n",
    "print(len(strcheck))\n",
    "strcheck = set(strcheck)\n",
    "print(len(strcheck))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntemp = []\\nfor k,v in target_index.items():\\n    temp.append(v)\\ntemp.sort()\\nprint(temp)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(len(pairsData))\n",
    "target_index = {}\n",
    "#target_index = {data[1]: idx for idx, data in enumerate(pairsData, start = 1)}\n",
    "\n",
    "m = 0\n",
    "\n",
    "for idx in range(len(pairsData)):\n",
    "    if not pairsData[idx][1] in target_index:\n",
    "        target_index[pairsData[idx][1]] = m\n",
    "        m = m + 1\n",
    " \n",
    "'''\n",
    "temp = []\n",
    "for k,v in target_index.items():\n",
    "    temp.append(v)\n",
    "temp.sort()\n",
    "print(temp)\n",
    "'''\n",
    "#index_target = {idx: data for data, idx in target_index.items()}\n",
    "#print(index_target[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = []\n",
    "\n",
    "for data in train_data:\n",
    "    finalData.append(tuple((source_index[data['paperAbstract1']], target_index[data['paperAbstract2']], data['label'])))\n",
    "    \n",
    "#print(finalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78098\n"
     ]
    }
   ],
   "source": [
    "## For generating negative samples\n",
    "finalData_Unique = set(finalData)\n",
    "print(len(finalData_Unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "source (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_embedding (Embedding)    (None, 1, 100)       4587100     source[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "target_embedding (Embedding)    (None, 1, 100)       3748400     target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           source_embedding[0][0]           \n",
      "                                                                 target_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1)            0           dot_product[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           reshape[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,335,502\n",
      "Trainable params: 8,335,502\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 100\n",
    "def model():\n",
    "    \n",
    "    source = Input(name = 'source', shape = [1])\n",
    "    target = Input(name = 'target', shape = [1])\n",
    "    \n",
    "    source_embedding = Embedding(name = 'source_embedding',input_dim = len(source_index),\n",
    "                               output_dim = embedding_size)(source)\n",
    "    \n",
    "    target_embedding = Embedding(name = 'target_embedding',input_dim = len(target_index),\n",
    "                               output_dim = embedding_size)(target)\n",
    "    \n",
    "    final_layer = Reshape([1])(Dot(name = 'dot_product', normalize = True, axes = 2)([source_embedding, target_embedding]))\n",
    "    \n",
    "    final_layer = Dense(1, activation = 'sigmoid')(final_layer)\n",
    "    model = Model(inputs = [source, target], outputs = final_layer)\n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(1000)\n",
    "\n",
    "def batchifier(finalData, batch_size, positive_samples, negative_samples):\n",
    "    batch = np.zeros((batch_size, 3))    \n",
    "    while True:\n",
    "\n",
    "        for idx, (source_id, target_id, label) in enumerate(random.sample(finalData, batch_size)):\n",
    "            #if label != ' ':\n",
    "            batch[idx, :] = (source_id, target_id, label)\n",
    "\n",
    "        '''\n",
    "        idx = idx + 1\n",
    "        while idx < batch_size:\n",
    "            \n",
    "            src = random.randrange(len(source_index))\n",
    "            tar = random.randrange(len(target_index))\n",
    "            if (src, tar) not in finalData_Unique:\n",
    "                batch[idx, :] = (src, tar, 0)\n",
    "                idx = idx + 1     \n",
    "        '''\n",
    "        np.random.shuffle(batch)\n",
    "        yield {'source': batch[:, 0], 'target': batch[:, 1]}, batch[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717\n",
      "307\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "positive_samples = math.ceil(batch_size * 0.7)\n",
    "negative_samples = math.floor(batch_size * 0.3)\n",
    "\n",
    "print(positive_samples)\n",
    "print(negative_samples)\n",
    "gen = batchifier(finalData, batch_size, positive_samples, negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'source': array([22976.,  1647., 17139., ...,   701., 24736., 28875.]),\n",
       "  'target': array([12915.,   199., 15328., ...,   553., 21470., 24745.])},\n",
       " array([1., 0., 1., ..., 0., 1., 1.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating Batch\n",
    "next(batchifier(finalData, batch_size, positive_samples = 2, negative_samples = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 - 1s - loss: 0.6730 - accuracy: 0.6185 - f1_m: 0.6925 - precision_m: 0.6761 - recall_m: 0.7102\n",
      "Epoch 2/2\n",
      "10/10 - 1s - loss: 0.6633 - accuracy: 0.6471 - f1_m: 0.7182 - precision_m: 0.6840 - recall_m: 0.7561\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# Steps_per_epoch = Training Size - too long\n",
    "h = model.fit(gen, epochs = 2,steps_per_epoch = 10, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/cs532/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /anaconda3/envs/cs532/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Desktop/word2vecModel_Dblp/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Desktop/word2vecModel_Dblp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 - 7s\n",
      "=======Predictions=======\n",
      "         0\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "...     ..\n",
      "1048571  0\n",
      "1048572  0\n",
      "1048573  0\n",
      "1048574  0\n",
      "1048575  0\n",
      "\n",
      "[1048576 rows x 1 columns]\n",
      "1024/1024 [==============================] - 8s 7ms/step - loss: 0.6898 - accuracy: 0.5400 - f1_m: 0.6402 - precision_m: 0.6099 - recall_m: 0.6736\n",
      "[0.6898403763771057, 0.5400390625, 0.6401917934417725, 0.6099004745483398, 0.673639714717865]\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "import pandas as pd\n",
    "pairsDataTest = []\n",
    "batch_size = 1024\n",
    "\n",
    "test_data = test_data[:1024]\n",
    "for data in test_data:\n",
    "    pairsDataTest.append(tuple((data['paperAbstract1'], data['paperAbstract2'], data['label'])))\n",
    "\n",
    "source_index_test = {}\n",
    "m = 0\n",
    "\n",
    "for idx in range(len(pairsDataTest)):\n",
    "    if not pairsDataTest[idx][0] in source_index_test:\n",
    "        source_index_test[pairsDataTest[idx][0]] = m\n",
    "        m = m + 1\n",
    "\n",
    "target_index_test = {}\n",
    "m = 0\n",
    "\n",
    "for idx in range(len(pairsDataTest)):\n",
    "    if not pairsDataTest[idx][1] in target_index_test:\n",
    "        target_index_test[pairsDataTest[idx][1]] = m\n",
    "        m = m + 1\n",
    "\n",
    "finalDataTest = []\n",
    "\n",
    "for data in test_data:\n",
    "    finalDataTest.append(tuple((source_index_test[data['paperAbstract1']], target_index_test[data['paperAbstract2']], data['label'])))\n",
    "    \n",
    "#print(finalDataTest)\n",
    "gen_test = batchifier(finalDataTest, batch_size, positive_samples = 2, negative_samples = 2)\n",
    "x,y = next(batchifier(finalData, batch_size, positive_samples = 2, negative_samples = 2))\n",
    "\n",
    "# Keeping Default Batch Size\n",
    "predictions = model.predict(gen_test, verbose = 2, steps = batch_size)\n",
    "#print(predictions)\n",
    "y_classes = predictions.argmax(axis=-1)\n",
    "df = pd.DataFrame(y_classes)\n",
    "print(\"=======Predictions=======\")\n",
    "print(df)\n",
    "\n",
    "## Retriving the Score\n",
    "score = model.evaluate(gen_test,verbose = 1, steps = batch_size)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizations\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
